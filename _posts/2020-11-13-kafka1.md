---
layout: post
title:  "1. Apache Kafka Introduction"
subtitle: "Apache Kafka Series"
date:   2020-11-13 00:00:00
categories: [design, tool]
---

_Apache Kafka is an open-source distributed event streaming platform_
-------------------------------------------------------------------------
Event streaming is set of different practices that handles:
* Capturing data in real-time from event sources like databases, sensors, mobile devices, cloud services, and software applications in the form of streams of events and store them   for later retrieval 
* Manipulating, processing, and reacting to the event streams in real-time and retrospectively.
* Routing the event streams to different destinations.
* Event streaming to ensure continuous flow so that the right data is at the right place, at the right time.


What is Kafka Capable of?
-------------------------------------------------------------------------
Kafka is end-to-end solution which combines three key capabilities:

* Publish (write) and subscribe to (read) streams of events, including continuous import/export of your data from other systems.
* To store streams of events durably and reliably for as long as you want.
* To process streams of events real-time or retrospectively.

It is distributed, highly scalable, elastic, fault-tolerant, and secure. 
Can be deployed on bare-metal hardware, virtual machines, and containers, and on-premises as well as in the cloud. 
You can choose between self-managing your Kafka environments and using fully managed services offered by a variety of vendors.

How are Messages Delivered?
-------------------------------------------------------------------------
Kafka deliver messages in threee diferent methods:
* At least once (Default) 
* At most once
* Exactly once

What is an Event/Message/Record?
-------------------------------------------------------------------------
An event records the fact that "something happened" in the world or in your business. 
When you read or write data to Kafka, you do this in the form of events. 
Conceptually, an event has a key, value, timestamp, and optional metadata headers. 

* Event key: "Alice"
* Event value: "Made a payment of $200 to Bob"
* Event timestamp: "Jun. 25, 2020 at 2:06 p.m."


Producers and Consumers
-----------------------------------------------------------------------

Producers are those client applications that publish (write) events to Kafka

Consumers are those that subscribe to (read and process) these events. 

In Kafka, producers and consumers are fully decoupled and agnostic of each other.


Brokers
-----------------------------------------------------------------------
Broker recieves messages from the producers, assigns offsets and stores the messages on disk.
Brokers are designed to operate in a cluster in which one broker is assigned the controller.
Brokers also replicate data across the cluster in order to ensure fault tolerance.




References:
https://kafka.apache.org/documentation/#introduction
https://kafka.apache.org/powered-by
